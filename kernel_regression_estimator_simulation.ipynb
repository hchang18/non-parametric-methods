{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kernel-regression-estimator-simulation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1O6BrcNikRsXY3TyS53verI-WGXqEU6nP",
      "authorship_tag": "ABX9TyPJOaf3ZkQ7OuD0EqjGpGCF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hchang18/non-parametric-methods/blob/main/kernel_regression_estimator_simulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhbvBOJq8ysD"
      },
      "source": [
        "## Kernel Regression Estimator Simulation\n",
        "### STAT 580 Non parametric methods (Spring 2021) \n",
        "\n",
        "### midterm exam\n",
        "Haeyoon Chang"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY7DZx-fMxMQ"
      },
      "source": [
        "1. Repeat your estimation 1000 times, each time you need to re-generate your data. \n",
        "    - generate data \n",
        "    - estimate optimal bandwidth\n",
        "    - estimate f_hat \n",
        "    - save it to f_hat for each x (1200 xs)\n",
        "      (for each x, there are 1000 f_hat)\n",
        "- calculate mean of f_hat for each x\n",
        "- calculate 2.5% and 97.5% percentiles of 1000 f_hats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldjyiMXRBqS4"
      },
      "source": [
        "# import libraries\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from scipy.stats import norm, expon\n",
        "\n",
        "from random import seed\n",
        "from random import randrange, uniform\n",
        "\n",
        "sns.set(color_codes=True)\n",
        "plt.rcParams[\"figure.figsize\"] = (20,15)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHcMfClrafHi"
      },
      "source": [
        "# ===================================================\n",
        "# Generate data                                     |\n",
        "# ===================================================\n",
        "def generate_data(n):\n",
        "    x = list()\n",
        "    y = list()\n",
        "\n",
        "    for i in range(n):\n",
        "        rand_x = uniform(-2, 10)\n",
        "        x.append(rand_x)\n",
        "        if rand_x < 1:\n",
        "            rand_y = (rand_x ** 2) / 20\n",
        "        elif 1 <= rand_x < 4:\n",
        "            rand_y = rand_x / 10 - 1 / 20\n",
        "        else:\n",
        "            rand_y = rand_x * np.sin(rand_x - 2.4) / 16 - 0.5 + 7 / 20\n",
        "    \n",
        "        eta = np.random.normal(0, 0.2)\n",
        "        y.append(rand_y + eta)\n",
        "        \n",
        "    x = np.array(x).reshape(n, 1)\n",
        "    y = np.array(y).reshape(n, 1)\n",
        "    data = np.hstack((np.array(y), np.array(x)))\n",
        "\n",
        "    return data, y, x"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_AAtBrdB2H4"
      },
      "source": [
        "# ============================================\n",
        "# Kernel Regression Estimator                |\n",
        "# ============================================\n",
        "def kernel_regression_estimator(data, kernel_func, bandwidth):\n",
        "    \"\"\" Generate kernel regression estimator over data.\"\"\"\n",
        "    X = data[:, 1]\n",
        "    Y = data[:, 0]\n",
        "    kernels = dict()\n",
        "    n = len(X)\n",
        "    for d in X:\n",
        "        kernels[d] = kernel_func(d, bandwidth)\n",
        "    def evaluate(x):\n",
        "        \"\"\"Evaluate `x` using kernels above.\"\"\"\n",
        "        resp = list()\n",
        "        weight = list()\n",
        "        for d in X:\n",
        "            resp.append(kernels[d](x))\n",
        "        resp_sum = sum(resp) # denominator\n",
        "        for i in range(n):\n",
        "            weight.append(resp[i]/resp_sum)\n",
        "        result = list()\n",
        "        for i in range(n):\n",
        "            result.append(weight[i]*Y[i])\n",
        "        return sum(result)\n",
        "    return (evaluate)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0qU9ylxBc31"
      },
      "source": [
        "# ============================================\n",
        "# Gaussian Kernel PDF                        |\n",
        "# ============================================\n",
        "def gaussian_pdf(x_i, bandwidth):\n",
        "    \"\"\"Return Gaussian kernel density estimator.\"\"\"\n",
        "    x_bar  = x_i\n",
        "    def evaluate(x):\n",
        "        \"\"\"Evaluate x.\"\"\"\n",
        "        pdf = (np.sqrt(2*np.pi*bandwidth**2)**-1) * np.exp(-((x - x_bar)**2)/(2*bandwidth**2))\n",
        "        return(pdf)\n",
        "    return(evaluate)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePDSxrXoncRh"
      },
      "source": [
        "# https://machinelearningmastery.com/implement-resampling-methods-scratch-python/\n",
        "def split_into_folds(dataset, folds=10):\n",
        "    dataset_split = list()\n",
        "    dataset_copy = list(dataset)\n",
        "    fold_size = int(len(dataset)/folds)\n",
        "    for i in range(folds):\n",
        "        fold = list()\n",
        "        while len(fold) < fold_size:\n",
        "            index = randrange(len(dataset_copy))\n",
        "            fold.append(dataset_copy.pop(index))\n",
        "        dataset_split.append(fold)\n",
        "    return dataset_split\n",
        "\n",
        "def split_test_train_set(dataset, k, test_idx):\n",
        "    folds = split_into_folds(dataset, folds=k)\n",
        "    test = np.array(folds[test_idx])\n",
        "    \n",
        "    train = list()\n",
        "    for i, x in enumerate(folds):\n",
        "        if i != test_idx:\n",
        "            train.extend(folds[i])\n",
        "    train = np.array(train)\n",
        "    return test, train"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-BI0etNKmQL"
      },
      "source": [
        "def estimate_bandwidth(data, kernel_function):\n",
        "    num_samples = len(data[:, 0])\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1]\n",
        "    # list of bandwidth \n",
        "    bandwidths = np.arange(0.01, 2, 0.02)\n",
        "\n",
        "    # estimate y_hat corresponding to X\n",
        "    errors = list()\n",
        "    k = 10\n",
        "    for h in bandwidths:\n",
        "        error = 0\n",
        "        folds = split_into_folds(data, k)\n",
        "        for i in range(k):\n",
        "            test, train = split_test_train_set(data, k, i)\n",
        "            estimator = kernel_regression_estimator(train, kernel_func=kernel_function, bandwidth=h)\n",
        "            y_hat = [estimator(x) for x in test[:, 1]]\n",
        "            error += (test[:, 0] - y_hat)**2\n",
        "        errors.append(sum(error))\n",
        "\n",
        "    errors = np.array(errors)\n",
        "    h_opt = bandwidths[np.argmin(errors)]\n",
        "    return h_opt                                                                                                        "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqlG0fl5R1Ul",
        "outputId": "ca9d9da9-8ed3-4a25-f5a0-3d94dfb8bb55"
      },
      "source": [
        "# repeat the estimation 1000 times\n",
        "f_hat_list = []\n",
        "\n",
        "for i in range(1000):\n",
        "    # generate data\n",
        "    n = 200\n",
        "    data, _ , _ = generate_data(n)\n",
        "    xi = data[:, 1]\n",
        "    x = np.arange(-2, 10, .1)\n",
        "    # estimate bandwidth - calculate on the first dataset\n",
        "    if i == 0:\n",
        "        h_cv = estimate_bandwidth(data, gaussian_pdf)\n",
        "        print(h_cv)\n",
        "    # estimate f_hat \n",
        "    estimator = kernel_regression_estimator(data, gaussian_pdf, bandwidth=h_cv)\n",
        "    y_hat = [estimator(i) for i in x]\n",
        "\n",
        "    f_hat_list.append(y_hat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24999999999999997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41IplZUIAtnc"
      },
      "source": [
        "# Compute the mean of 1000 estimation f_hat\n",
        "f_hat_arr = np.array(f_hat_list)\n",
        "mean = f_hat_arr.mean(axis=0)\n",
        "lower_bound = np.percentile(f_hat_arr, 2.5, axis=0)\n",
        "upper_bound = np.percentile(f_hat_arr, 97.5, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dcg57E8C9xy"
      },
      "source": [
        "# true function graph \n",
        "def true_function():\n",
        "    y_list = list()\n",
        "    x_arr = np.arange(-2, 10, .1)\n",
        "    n = len(x_arr)\n",
        "\n",
        "    for x in x_arr:\n",
        "        if x < 1:\n",
        "            y = (x ** 2) / 20\n",
        "        elif 1 <= x < 4:\n",
        "            y = x / 10 - 1 / 20\n",
        "        else:\n",
        "            y = x * np.sin(x - 2.4) / 16 - 0.5 + 7 / 20\n",
        "    \n",
        "        # eta = np.random.normal(0, 0.2)\n",
        "        y_list.append(y)\n",
        "        \n",
        "    x = x_arr.reshape(n, 1)\n",
        "    y = np.array(y_list).reshape(n, 1)\n",
        "    data = np.hstack((np.array(y), np.array(x)))\n",
        "\n",
        "    return data, y, x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuBNMIfeVpVs"
      },
      "source": [
        "_, true_y, _ = true_function()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_lxfe0pVVcp"
      },
      "source": [
        "# plot of mean, bottom 2.5 percent, upper 2.5 percent, and true function \n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(2, 2, 1)\n",
        "g = ax.grid(True)\n",
        "ax.plot(x, mean, label='mean')\n",
        "ax.plot(x, true_y, label='true function')\n",
        "ax.plot(x, lower_bound, label='2.5 percentile')\n",
        "ax.plot(x, upper_bound, label='97.5 percentile')\n",
        "leg = ax.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}